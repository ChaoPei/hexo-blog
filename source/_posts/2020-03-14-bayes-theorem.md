---
title: 贝叶斯定理
date: 2020-03-14 19:38:13
update: 2020-03-14 19:38:13
categories: MachineLearning
tags: [机器学习, 贝叶斯定理, 概率论]
mathjax: true
---

贝叶斯定理的理解对于概率计算是非常重要，而且日常使用非常常见。

<!-- more -->

### 引言

我们日常计算概率，最简单的就是正向概率。比如一个抽奖活动，抽奖桶里有 10 个球，其中 2 个白球，8 个黑球，抽到白球就算你中奖。你伸手进去随便摸出 1 颗球，摸出中奖球的概率是多大。根据概率计算公式可知是 2/10。

**正向概率是已知事件空间的概率分布，求某个事件发生的概率**，这在日常生活中并不常见，除了抽奖。日常常见的是发生了某件事，比如天上有乌云，我要知道下雨的概率。这类**利用有限的信息预测可能发生的事件概率**在生活中无处不在，也是算法所要解决的问题，而贝叶斯定理解决的是就是这类问题。贝叶斯定理的用处可以总结为一句话：**在有限的信息下，能够帮助我们预测出概率**。

### 贝叶斯定理

$$
P(A|B) = P(A) \frac {P(B|A)} {P(B)}
$$

在介绍贝叶斯定理之前，简单介绍概率论相关知识点：

* $P(A)$ 表示事件 A 发生的概率。
* $P(AB)$ 表示事件 A 和事件 B 同时发生的概率。
* $P(B|A)$ 表示在事件 A 发生的前提下，事件 B 发生的概率。

很明显，贝叶斯定理所要求解的问题就是$P(A|B)$ 这种概率，也就是在已知事件 B 的情况下，求事件 A 发生的概率。为此，我们还需要了解一些关于概率的名词。

#### 先验概率

$P(A)$ 是先验概率（prior probability），先验概率就是已知的概率分布，比如投一个正常骰子的每个点数的概率是 1/6，抛一枚正常硬币正面和反面的概率都是 1/2。

#### 可能性函数

$P(B|A)/P(B)$ 称为“可能性函数”（likelyhood），这是一个调整因子，即新信息 $B$ 带来的调整，作用 是**使得先验概率更接近真实概率**。 可能性函数你可以理解为新信息过来后，对先验概率的一个调整。

#### 后验概率

$P(A|B)$ 是后验概率（posterior probability），即在 B 事件发生之后，我们对 A 事件概率的重新评估，也就是贝叶斯定理求解所期望的更加真实的概率。

现在我们再看一遍贝叶斯公式，你现在就能明白这个公式背后的最关键思想了： 我们先根据以往的经验预估一个先验概率 $P(A)$，然后加入新的信息（事件 B），这样有了新的信息后，我们对事件 A 的预测就更加准确。 因此，贝叶斯定理可以理解成下面的式子： 

**后验概率（新信息出现后的A概率）＝ 先验概率（A概率）ｘ 可能性函数（新信息带来的调整）**

为什么需要像贝叶斯这样做呢？前面已经解释了，一个事件比如下雨，发生的概率是受非常多因素的影响，那么我们如果预测天气呢，其实就是把能够考虑到的信息都计算进去，然后不断修正先验概率，得到后验概率。这里有一个朴素的思想：如果我能掌握一个事情的全部信息，我当然能计算出一个客观概率（古典概率）。但是当我们手中只有有限的信息。既然无法得到全面的信息，我们就在信息有限的情况下，尽可能做出一个好的预测。也就是，在主观判断的基础上，你可以先估计一个值，然后根据观察的新信息不断修正(可能性函数)。

### 应用案例

贝叶斯定理很简单，但是最难的是将简单的公式应用到实际解决问题当中去，这也是对定理深刻的理解。

#### 案例 1

假设有两个一模一样的碗，1 号碗里有 30 个巧克力和 10 个水果糖，2 号碗里有 20 个巧克力和 20 个水果糖。现在随机选择一个碗，从里面摸出一个巧克力。 问这颗巧克力来自 1 号碗的概率是多少？

我们一步步来求解。

首先把问题分解，问题的事件 A 是要求取的后验概率，因此定义事件 A 就是选择了 1 号碗的概率。而事件 B 是已经发生的事，也就是摸出了一颗巧克力，因此定义事件 B 为取出一个巧克力。所以 $P(A|B)$ 就表示取出一颗巧克力，其来自 1 号碗的概率。。

现在我们先分别计算 $P(A)$ 和 $P(B)$ 。因为碗一样，所以 $P(A)$ 肯定是 1/2。$P(B)$ 用古典概率分布也很容易求出：
$$
P(B) = 0.5 \times \frac {30} {40} + 0.5 \times \frac {20} {40} = 0.625
$$
也就是说在未知情况下，取出巧克力的先验概率是 0.625。接着计算 $P(B|A)$ 也很简单，就是确定选择了 1 号碗，取出巧克力的概率很明显是 0.75。因此可能性函数就是：
$$
\frac {P(B|A)} {P(B)} = \frac {0.75} {0.625} = 1.2
$$


很明显，可能性增强了。表明事件 B 对事件 A 发生的概率产生了增益。其实我们看题目也明白，1 号碗中巧克力的比例更大，因此如果选择了 1 号碗（事件 A）发生，必然取得巧克力（事件 B）的概率也变大了。

后验概率计算：
$$
P(A|B) = P(A) \frac {P(B|A)} {P(B)} = 0.5 \times 1.2 = 0.6
$$
可以看到，如果是盲猜，那么这颗巧克力不是来自 1 号碗就是来自 2 号碗，二者概率均为 0.5。但是运用贝叶斯定理，因为两个碗里的巧克力比例不同，盲猜的先验概率得到了修正，来自 1 号碗的概率更大。这也是符合日常常识的。

总结下刚才的贝叶斯定理应用的套路：

1. 首先分解问题，简单来说就像做应用题的感觉，先列出解决这个问题所需要的一些条件，然后记清楚哪些是已知 的，哪些是未知的，已知条件是什么。
2. 应用贝叶斯定理，求贝叶斯公式中的 2 个指标：先验概率和可能性函数，然后带入贝叶斯公式求后验概率。

#### 案例 2

假设某种疾病的发病率是 0.001，即 1000 人中会有 1 个人得病。现有一种试剂可以检验患者是否得病，它的准确率是 0.99，即在患者确实得病的情况下，它有 99% 的可能呈现阳性。它的误报率是 5%，即在患者没有得病的情况下，它有 5% 的可能呈现阳性。现有一个病人的检验结果为阳性，请 问他确实得病的可能性有多大？

我们一步步分解来看。

已知事件B：检验结果为阳性。求解事件A：确实得病。可以利用古典概率公式分别求二者的概率：
$$
P(B)=0.001 \times 0.99 + (1-0.001) \times 0.05=0.05094
$$
右边第一项是得病的人，检测结果为阳性，第二项是没病得人，检测结果为阳性。
$$
P(A)=0.001
$$
$P(B|A)$  就是得病了，检测结果为阳性，很明显就是0.99，因此可能性函数也可以很容易求得：
$$
\frac{P(B|A)}{P(B)} =\frac{0.99}{0.05094}=19.435
$$
最后运用贝叶斯公式：
$$
P(A|B) = P(A) \frac {P(B|A)} {P(B)} = 0.001 \times 19.435 = 0.0194
$$
也就是检测正确率很高的情况下，检测结果成阳性，其真正得病的概率也才 0.0194，这是不是很不符合我们平时的感觉？这就是贝叶斯公式的厉害之处。我们看一下这里问题出在哪里呢？其实很简单，就是真实得病率太低了，虽然检测结果为阳性这个事件已经将其发生概率提升了 19 倍多。这就是为什么医学检查通常要做很多次，特别是像艾滋病这种发病率很低的病。

### 总结

贝叶斯定理因为其强大的内在原理和广泛的应用场景，因此成为机器学习的基础，衍生出很多应用方式。其实更厉害的是其思想，也就是分解问题、主观判断、搜集信息、修正判断。这一套逻辑不仅仅是概率，更是日常生活中我们做事情、学习的逻辑。